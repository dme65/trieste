:py:mod:`trieste.models.gpflux`
===============================

.. py:module:: trieste.models.gpflux

.. autoapi-nested-parse::

   This package contains the primary interface for deep Gaussian process models. It also contains a
   number of :class:`TrainableProbabilisticModel` wrappers for GPflux-based models. Note that currently
   copying/saving models is not supported, so in a Bayes Opt loop `track_state` should be set False.



Package Contents
----------------

.. py:class:: GPfluxModelConfig

   Bases: :py:obj:`trieste.models.config.ModelConfig`

   Specification for building a GPflux instance of
   :class:`~trieste.models.TrainableProbabilisticModel`. Note that `optimizer_args` are not used
   for GPflux models.

   .. py:method:: supported_models(self) -> dict[Any, collections.abc.Callable[[Any, tensorflow.optimizers.Optimizer], trieste.models.interfaces.TrainableProbabilisticModel]]

      Defines all models supported by certain model type (e.g. Gaussian process implementation).
      This method has to be specified by a model type specific subclass.

      :return: A mapping of third-party model types to :class:`CustomTrainable` classes that wrap
          models of those types.


   .. py:method:: create_model_interface(self) -> trieste.models.interfaces.TrainableProbabilisticModel

      :return: A model built from this model configuration.



.. py:class:: GPfluxPredictor(name=None)

   Bases: :py:obj:`trieste.models.interfaces.ProbabilisticModel`, :py:obj:`tensorflow.Module`, :py:obj:`abc.ABC`

   A trainable wrapper for a GPflux deep Gaussian process model. The code assumes subclasses
   will use the Keras `fit` method for training, and so they should provide access to both a
   `model_keras` and `model_gpflux`. Note: due to Keras integration, the user should remember to
   use `tf.keras.backend.set_floatx()` with the desired value (consistent with GPflow) to avoid
   dtype errors.

   .. py:method:: model_gpflux(self) -> gpflow.base.Module
      :property:

      The underlying GPflux model.


   .. py:method:: model_keras(self) -> tensorflow.keras.Model
      :property:

      Returns the compiled Keras model for training.


   .. py:method:: optimizer(self) -> tensorflow.keras.optimizers.Optimizer
      :property:

      The optimizer with which to train the model.


   .. py:method:: predict(self, query_points: trieste.types.TensorType) -> tuple[trieste.types.TensorType, trieste.types.TensorType]

      Note: unless otherwise noted, this returns the mean and variance of the last layer
      conditioned on one sample from the previous layers.


   .. py:method:: predict_joint(self, query_points: trieste.types.TensorType) -> tuple[trieste.types.TensorType, trieste.types.TensorType]
      :abstractmethod:

      :param query_points: The points at which to make predictions, of shape [..., B, D].
      :return: The mean and covariance of the joint marginal distribution at each batch of points
          in ``query_points``. For a predictive distribution with event shape E, the mean will
          have shape [..., B] + E, and the covariance shape [...] + E + [B, B].


   .. py:method:: sample(self, query_points: trieste.types.TensorType, num_samples: int) -> trieste.types.TensorType
      :abstractmethod:

      Return ``num_samples`` samples from the independent marginal distributions at
      ``query_points``.

      :param query_points: The points at which to sample, with shape [..., N, D].
      :param num_samples: The number of samples at each point.
      :return: The samples. For a predictive distribution with event shape E, this has shape
          [..., S, N] + E, where S is the number of samples.


   .. py:method:: predict_y(self, query_points: trieste.types.TensorType) -> tuple[trieste.types.TensorType, trieste.types.TensorType]

      Note: unless otherwise noted, this will return the prediction conditioned on one sample
      from the lower layers.


   .. py:method:: get_observation_noise(self) -> trieste.types.TensorType

      Return the variance of observation noise for homoscedastic likelihoods.

      :return: The observation noise.
      :raise NotImplementedError: If the model does not have a homoscedastic likelihood.



